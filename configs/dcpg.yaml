# Directory
log_dir: /logs
output_dir: /outputs
save_dir: /models
wandb_dir: /wandb

# Weights & Biases
project_name: "phasic-exploration--dcpg"
model_name: "DCPG - Teleport RND smaller"

# Experiment
log_interval: 10
num_eval_episodes: 100

# Environment
distribution_mode: easy
num_levels: 200
start_level: 0
num_env_steps: 2.5e+7
normalize_reward: True

# Rollout
num_processes: 64
num_steps: 256

# Policy gradient
gamma: 0.999
gae_lambda: 0.95

# Actor-critic
actor_critic_class: PPOModel
actor_critic_params:
  shared: True

# State buffer
# state_buffer_size: 16_448 # 64*257
state_buffer_size: 4112 # 16*257
prob_to_teleport: .8
teleport_warmup: 1_000_000
use_rnd: True
rnd_epoch: 2
buffer_type: "RND"
add_batch_size: 32 

# Agent
agent_class: DCPG
agent_params:
  # PPO params
  clip_param: 0.2
  ppo_epoch: 1
  num_mini_batch: 8
  entropy_coef: 0.01
  lr: 5.0e-4
  eps: 1.0e-5
  max_grad_norm: 0.5
  # Aux params
  buffer_size: 32
  aux_epoch: 6
  aux_freq: 32
  aux_num_mini_batch: 16
  policy_dist_coef: 1.0
  value_dist_coef: 1.0
